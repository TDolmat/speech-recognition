{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry3pnR0H9TM6",
        "outputId": "7f3ae8f5-60be-45ba-9d98-f4fa88b77099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "J2LrT9_3yYBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flashlight-text\n",
        "!pip install kenlm\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T1Lin8h9haW",
        "outputId": "6f811b3a-0923-46bc-eccc-b7495e466b74"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flashlight-text in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: kenlm in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "TqUqJJ8wyfMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ACOUSTIC_MODEL_FILE = '/content/drive/MyDrive/speech_recognition/demo_model.pt'\n",
        "\n",
        "TEMP_AUDIO_FILE = 'temp.wav'\n",
        "SAMPLE_RATE = 32000\n",
        "\n",
        "# CTC beam search decoder\n",
        "LM_WEIGHT = 3.23\n",
        "WORD_SCORE = -0.26\n",
        "LEXICON_FILE = '/content/drive/MyDrive/speech_recognition/lexicon.txt'\n",
        "TOKENS_FILE = '/content/drive/MyDrive/speech_recognition/tokens.txt'\n",
        "LANGUAGE_MOREL_FILE = '/content/drive/MyDrive/speech_recognition/lm.bin'\n",
        "N_GRAMS = 3\n",
        "BEAM_SIZE = 1500"
      ],
      "metadata": {
        "id": "GFgCJWaDye04"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "c-ZAfOu9xsGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "import IPython\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "import time\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from torchaudio.models.decoder import ctc_decoder\n",
        "from torchaudio.utils import download_asset\n",
        "\n",
        "from jiwer import wer, cer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "KwvU_YcVxSvS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google colab audio recording"
      ],
      "metadata": {
        "id": "ZittbHrtyGyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def record_and_save(seconds=3, temp_file=\"audio_temp.wav\"):\n",
        "    RECORD = \"\"\"\n",
        "    const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "    const b2text = blob => new Promise(resolve => {\n",
        "    const reader = new FileReader()\n",
        "    reader.onloadend = e => resolve(e.srcElement.result)\n",
        "    reader.readAsDataURL(blob)\n",
        "    })\n",
        "    var record = time => new Promise(async resolve => {\n",
        "    stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "    recorder = new MediaRecorder(stream)\n",
        "    chunks = []\n",
        "    recorder.ondataavailable = e => chunks.push(e.data)\n",
        "    recorder.start()\n",
        "    await sleep(time)\n",
        "    recorder.onstop = async ()=>{\n",
        "        blob = new Blob(chunks)\n",
        "        text = await b2text(blob)\n",
        "        resolve(text)\n",
        "    }\n",
        "    recorder.stop()\n",
        "    })\n",
        "    \"\"\"\n",
        "\n",
        "    def record(sec):\n",
        "        display(Javascript(RECORD))\n",
        "        s = output.eval_js('record(%d)' % (sec*1000 + 1500))\n",
        "        b = b64decode(s.split(',')[1])\n",
        "        with open(temp_file,'wb+') as f:\n",
        "            f.write(b)\n",
        "        return 'saved'\n",
        "\n",
        "    print(f\"Wait 3 seconds and speak to your microphone for {seconds} seconds...\")\n",
        "    record(seconds)\n",
        "    print(\"Done recording!\")\n",
        "\n",
        "    speech, rate = librosa.load(temp_file)\n",
        "    write('audio_temp.wav', rate, speech)"
      ],
      "metadata": {
        "id": "43ou6Ya7SujF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading acoustic model"
      ],
      "metadata": {
        "id": "5d9y3MM7yMUM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "OjssYTcSHIBA"
      },
      "outputs": [],
      "source": [
        "acoustic_model = torch.jit.load(ACOUSTIC_MODEL_FILE)\n",
        "\n",
        "def model_predict(audio_file):\n",
        "    if audio_file == None:\n",
        "        print(\"[Error] No audio file provided\")\n",
        "\n",
        "    waveform, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "    if sample_rate != SAMPLE_RATE:\n",
        "        waveform = torchaudio.functional.resample(waveform, sample_rate, SAMPLE_RATE)\n",
        "\n",
        "    model_output, _ = acoustic_model(waveform)\n",
        "    return model_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoders"
      ],
      "metadata": {
        "id": "I8EMJ2Vsx2kR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps7MBPtOHIBC"
      },
      "source": [
        "## Beam Search Decoder\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "86-q56QJHIBC"
      },
      "outputs": [],
      "source": [
        "beam_search_decoder = ctc_decoder(\n",
        "    lexicon=LEXICON_FILE,\n",
        "    tokens=TOKENS_FILE,\n",
        "    lm=LANGUAGE_MOREL_FILE,\n",
        "    nbest=N_GRAMS,\n",
        "    beam_size=BEAM_SIZE,\n",
        "    lm_weight=LM_WEIGHT,\n",
        "    word_score=WORD_SCORE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViAp_BvwHIBC"
      },
      "source": [
        "## Greedy Decoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JUzgPiucHIBC"
      },
      "outputs": [],
      "source": [
        "tokens = []\n",
        "with open(TOKENS_FILE, 'r') as tokens_file:\n",
        "    tokens = tokens_file.read().split('\\n')\n",
        "\n",
        "class GreedyCTCDecoder(torch.nn.Module):\n",
        "    def __init__(self, labels, blank=0):\n",
        "        super().__init__()\n",
        "        self.labels = labels\n",
        "        self.blank = blank\n",
        "\n",
        "    def forward(self, emission: torch.Tensor) -> List[str]:\n",
        "        indices = torch.argmax(emission, dim=-1)\n",
        "        indices = torch.unique_consecutive(indices, dim=-1)\n",
        "        indices = [i for i in indices if i != self.blank]\n",
        "        joined = \"\".join([self.labels[i] for i in indices])\n",
        "        return joined.replace(\"|\", \" \").strip().split()\n",
        "\n",
        "\n",
        "greedy_decoder = GreedyCTCDecoder(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoding result"
      ],
      "metadata": {
        "id": "OSP31-1Ux94i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_greedy_result(model_output):\n",
        "    return \" \".join(greedy_decoder(model_output[0]))\n",
        "\n",
        "def get_beam_search_result(model_output):\n",
        "    return \" \".join(beam_search_decoder(model_output)[0][0].words).strip()"
      ],
      "metadata": {
        "id": "nkNN7Scfe2O9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo main"
      ],
      "metadata": {
        "id": "TrXKIYqGypyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def record_predict_and_evaluate(recording_time=5):\n",
        "    record_and_save(seconds=recording_time, temp_file=TEMP_AUDIO_FILE)\n",
        "\n",
        "    model_output = model_predict(TEMP_AUDIO_FILE)\n",
        "\n",
        "    greedy_result = get_greedy_result(model_output)\n",
        "    beam_search_result = get_beam_search_result(model_output)\n",
        "    print(f'\\n\\n=========================== PREDICTION RESULTS ===========================')\n",
        "    print(f'\\nGREEDY RESULT:\\n{greedy_result}')\n",
        "    print(f'\\nBEAM SEARCH RESULT:\\n{beam_search_result}')\n",
        "\n",
        "    print(f'\\n\\n============================== EVALUATION ===============================')\n",
        "    actual_sentance = input('\\nENTER ACTUAL SENTANCE:\\n').lower()\n",
        "\n",
        "    if len(actual_sentance) == 0:\n",
        "        print('\\n=========================================================================')\n",
        "        return\n",
        "\n",
        "    gready_wer = wer(actual_sentance, greedy_result)\n",
        "    gready_cer = cer(actual_sentance, greedy_result)\n",
        "\n",
        "    beam_search_wer = wer(actual_sentance, beam_search_result)\n",
        "    beam_search_cer = cer(actual_sentance, beam_search_result)\n",
        "\n",
        "    print(f'\\nGREEDY:\\n   WER: {gready_wer:.2f}\\n   CER: {gready_cer:.2f}')\n",
        "    print(f'\\nBEAM SEARCH:\\n   WER: {beam_search_wer:.2f}\\n   CER: {beam_search_cer:.2f}')\n",
        "    print('\\n=========================================================================')"
      ],
      "metadata": {
        "id": "liJoJJz1yr-U"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q6_M7B8HIBC"
      },
      "source": [
        "# Run demo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "record_predict_and_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "RrwY6WYRcJbH",
        "outputId": "150921b6-3b52-4be2-cc37-138eae341192"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wait 3 seconds and speak to your microphone for 5 seconds...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "    const b2text = blob => new Promise(resolve => {\n",
              "    const reader = new FileReader()\n",
              "    reader.onloadend = e => resolve(e.srcElement.result)\n",
              "    reader.readAsDataURL(blob)\n",
              "    })\n",
              "    var record = time => new Promise(async resolve => {\n",
              "    stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "    recorder = new MediaRecorder(stream)\n",
              "    chunks = []\n",
              "    recorder.ondataavailable = e => chunks.push(e.data)\n",
              "    recorder.start()\n",
              "    await sleep(time)\n",
              "    recorder.onstop = async ()=>{\n",
              "        blob = new Blob(chunks)\n",
              "        text = await b2text(blob)\n",
              "        resolve(text)\n",
              "    }\n",
              "    recorder.stop()\n",
              "    })\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done recording!\n",
            "\n",
            "\n",
            "=========================== PREDICTION RESULTS ===========================\n",
            "\n",
            "GREEDY RESULT:\n",
            "ther praviost solifene was to god\n",
            "\n",
            "BEAM SEARCH RESULT:\n",
            "the previous solution was too good\n",
            "\n",
            "\n",
            "============================== EVALUATION ===============================\n",
            "\n",
            "ENTER ACTUAL SENTANCE:\n",
            "the previous solution wat too good\n",
            "\n",
            "GREEDY:\n",
            "   WER: 1.00\n",
            "   CER: 0.35\n",
            "\n",
            "BEAM SEARCH:\n",
            "   WER: 0.17\n",
            "   CER: 0.03\n",
            "\n",
            "=======================================================================\n"
          ]
        }
      ]
    }
  ]
}